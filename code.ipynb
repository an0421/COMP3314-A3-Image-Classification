{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting HOG features: 100%|██████████| 50000/50000 [00:28<00:00, 1727.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting HOG features: 100%|██████████| 10000/10000 [00:05<00:00, 1715.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM model...\n",
      "Making predictions on test data...\n",
      "Submission file saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the HOGFeatureExtractor class\n",
    "class HOGFeatureExtractor:\n",
    "    def __init__(self, resize_shape=(64, 64), orientations=12, pixels_per_cell=(8, 8),\n",
    "                 cells_per_block=(4, 4), block_norm='L2-Hys', n_components=256):\n",
    "        self.resize_shape = resize_shape\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "        self.block_norm = block_norm\n",
    "        self.n_components = n_components\n",
    "        self.scaler = StandardScaler()\n",
    "        self.pca = PCA(n_components=n_components)\n",
    "\n",
    "    def preprocess_image(self, image_path):\n",
    "        # Read image in grayscale\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Image {image_path} cannot be loaded.\")\n",
    "        # Resize image\n",
    "        img = cv2.resize(img, self.resize_shape)\n",
    "        return img\n",
    "\n",
    "    def extract_hog_features(self, image):\n",
    "        # Extract HOG features\n",
    "        features = hog(\n",
    "            image,\n",
    "            orientations=self.orientations,\n",
    "            pixels_per_cell=self.pixels_per_cell,\n",
    "            cells_per_block=self.cells_per_block,\n",
    "            block_norm=self.block_norm,\n",
    "            visualize=False\n",
    "        )\n",
    "        return features\n",
    "\n",
    "    def prepare_data_with_hog(self, file_paths):\n",
    "        features = []\n",
    "        for path in tqdm(file_paths, desc=\"Extracting HOG features\"):\n",
    "            try:\n",
    "                img = self.preprocess_image(path)\n",
    "                hog_features = self.extract_hog_features(img)\n",
    "                features.append(hog_features)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {path}: {e}\")\n",
    "                continue\n",
    "        return np.array(features)\n",
    "\n",
    "    def fit_scaler(self, X):\n",
    "        self.scaler.fit(X)\n",
    "        return self.scaler.transform(X)\n",
    "\n",
    "    def transform_scaler(self, X):\n",
    "        return self.scaler.transform(X)\n",
    "\n",
    "    def fit_pca(self, X):\n",
    "        self.pca.fit(X)\n",
    "        return self.pca.transform(X)\n",
    "\n",
    "    def transform_pca(self, X):\n",
    "        return self.pca.transform(X)\n",
    "\n",
    "# Load train.csv and test.csv\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Assuming 'file_path' columns are 'im_name' in your CSV files\n",
    "train_image_paths = train_df['im_name'].apply(lambda x: os.path.join('train_ims', x))\n",
    "test_image_paths = test_df['im_name'].apply(lambda x: os.path.join('test_ims', x))\n",
    "\n",
    "# Extract labels for training data\n",
    "y_train = train_df['label'].values\n",
    "\n",
    "# Initialize HOGFeatureExtractor\n",
    "hog_extractor = HOGFeatureExtractor(\n",
    "    resize_shape=(64, 64),\n",
    "    orientations=12,\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(4, 4),\n",
    "    block_norm='L2-Hys',\n",
    "    n_components=256\n",
    ")\n",
    "\n",
    "# Extract HOG features for training data\n",
    "print(\"Processing training data...\")\n",
    "X_train_features = hog_extractor.prepare_data_with_hog(train_image_paths)\n",
    "\n",
    "# Extract HOG features for test data\n",
    "print(\"Processing test data...\")\n",
    "X_test_features = hog_extractor.prepare_data_with_hog(test_image_paths)\n",
    "\n",
    "# Fit and transform scaler on training data\n",
    "X_train_scaled = hog_extractor.fit_scaler(X_train_features)\n",
    "# Transform scaler on test data\n",
    "X_test_scaled = hog_extractor.transform_scaler(X_test_features)\n",
    "\n",
    "# Fit and transform PCA on training data\n",
    "X_train_pca = hog_extractor.fit_pca(X_train_scaled)\n",
    "# Transform PCA on test data\n",
    "X_test_pca = hog_extractor.transform_pca(X_test_scaled)\n",
    "\n",
    "# Initialize SVM model\n",
    "svc_model = SVC(kernel='rbf', C=5, random_state=42)\n",
    "# Train the model on the full training data\n",
    "print(\"Training SVM model...\")\n",
    "svc_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "print(\"Making predictions on test data...\")\n",
    "test_predictions = svc_model.predict(X_test_pca)\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission = test_df.copy()\n",
    "submission['label'] = test_predictions\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as 'submission.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
